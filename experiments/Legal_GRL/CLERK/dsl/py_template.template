# Execution of ToT domain modeling tasks
import argparse
from ast import literal_eval
from dsl.tree import Tree
from dsl.input import Input
from dsl.modelingProblem import ModelingProblem as Problem
from dsl.modelingTask import ModelingTask as Task

LEVELS = {{ model.tasks | length }}
N_SAMPLES = {{ model.tree.number_samples }}
N_VOTES = {{ model.tree.number_votes }}
INPUT_ARGS = literal_eval("{{input_data}}")

def CLERK(args):
    input = Input()
    input.process_input(args, INPUT_ARGS)
    LOG_NAME = f"output_{input.get_name()}"

    problem = Problem(purpose = """{{model.problem.purpose}}""", input = input, levels = LEVELS)
    tree = Tree(n_samples = N_SAMPLES, n_votes = N_VOTES, n_levels = LEVELS)
    tree.set_problem(problem = problem)

    modelingTasks = [None for _ in range(LEVELS)]
    {% for task in model.tasks %}
    {% set outer_loop = loop %}
    modelingTasks[{{outer_loop.index0}}] = Task(level = {{outer_loop.index0 + 1}}, name = "{{task.name}}")
    modelingTasks[{{outer_loop.index0 }}].set_description("""{{task.description}}""")
    {% for criterion in task.assessments %}
    modelingTasks[{{outer_loop.index0 }}].add_assessment("""{{criterion}}""")
    {% endfor %}
    problem.add_task(task = modelingTasks[{{outer_loop.index0}}])
    {% endfor %}

    tree.setup_tree()
    output = tree.execute(LOG_NAME)

    print(f'Tree of thoughts executed for {problem.get_purpose()}, the result is located in {LOG_NAME}')

TYPE_MAP = { "FILE": str, "STR": str, "INT": int}

def parse_args():
    args = argparse.ArgumentParser()
    for name, input in INPUT_ARGS.items():
        py_type = TYPE_MAP.get(input["type"].lower(), str)
        is_required = not input["isOptional"]
        args.add_argument(f'--{name}', type=py_type, required=is_required, default='')
    args = args.parse_args()
    return args
    
if __name__ == '__main__':
    args = parse_args()
    CLERK(args)